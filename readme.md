# 长对话结构化总结工作流调优

欢迎参观我的prompt调优工程。这个工程的主要目标是让大模型在处理以pdf形式储存的人机对话时，可以将发散性的对话整理成结构化的成果，同时不被分歧和争论误导，忽略被推翻的结论，只整理经过验证或确认的最终结论。简而言之，就是将发散性的讨论，转化为结构化的、精准的成果。

---

## 痛点与项目目标
做这个prompt优化工程的起因是，在我自己设计AI产品的过程中，会和AI进行发散性的头脑风暴。但对话结束后，无法结构化这些资产则是无法解决的痛点：
- 直接让AI总结对话，因为记忆和输出限制，丢失大部分内容。
- 安装插件，将对话历史导出为pdf，导入到NotebookLM，在NotebookLM生成总结。
这样的痛点，还存在于会议记录的处理等场景，对话通常是发散的、非线性的，且包含大量“反转”（先同意后否决）。

但是单纯依靠市面上的大模型的原生功能，要实现结构化和精准化的总结并不容易。主要实现难点是：
- 输出token有限，无法完全总结内容，或者过度总结内容，丢失细节。
- 如果没有合适的prompt，无法产出结构合理的内容，容易产生幻觉。
- 无法理解对话的发散性，和反复推倒重建的推理过程。无法定位最终结论，将已经被推翻的结论纳入总结。
- 无法理解AI回答的发散性，归纳过多AI提出但用户没有明确回应或没办法及时回应的反对方案（默认否决）。

---

## 评估流程
**评估样本：**
一到两个长对话pdf，每段完整对话需要包含十个发生在不同时序的决策反转，以及跳跃性切换话题。

**评估指标：**
- 指标 A：准确率
     - 测试逻辑：计算十个被否决的方案中，模型能够识别出的个数。
     
- 指标 B：完整性 
    - 测试逻辑：设计五个距离父话题至少20个对话回合的子话题，计算正确归纳进父话题的个数。

- 指标 C：幻觉率 (Hallucination Rate)
    - 测试逻辑：大模型输出不实内容的数量占整体内容的比例。

---

## 调优后的工作流(Ver.4)：
1. 将pdf清洗为带时序的text文档。将行号嵌入到每一行文本，行号的大小代表着对话发生的先后次序，减少幻觉和时序识别错误。
2. 粗略总结对话，生成带行号索引的“思维导图”，输出格式为JSON。合并同类话题，将子话题归纳入父话题。
3. 将JSON按照话题切分为若干个JSON文件。
4. 逐个处理切分后的JSON文件。基于索引回溯原文，审计每个方案的最终状态（是否被否决，或默认否决）。
5. 将清洗后的事实组装为Markdown报告。

---

## 版本迭代

| **版本**          | **抓取逻辑**                          | **辨认逻辑**                  | **核心缺陷**               | 迭代方案                                |
| --------------- | --------------------------------- | ------------------------- | ---------------------- | ----------------------------------- |
| **Ver. 1 (直觉)** | 大模型视觉处理、关键词                       | 全文通读、模糊总结                 | 幻觉、无法识别被否决方案           | 标准化对话的时序                            |
| **Ver. 2 (工程)** | 将pdf清洗为text、<br>行号索引              | 逐段判定、逐段标签、<br>逐标签总结       | 机械、冗长、<br>总结文档包含过多推理过程 | 细化文档生成原则、<br>在抓取阶段引入CoT             |
| **Ver. 3 (意图)** | 将pdf清洗为text、<br>行号索引              | 逐段判定、逐段标签、<br>逐标签总结       | 生成慢、<br>token消耗过多      | 减少单次输入、<br>放弃逐段处理、<br>减少prompt包含的步骤 |
| **Ver. 4 (效率)** | 将pdf清洗为text、<br>行号索引<br>按话题切分JSON | 分段处理、<br>放弃标签、<br>合并判定和决策 | 精准度些许下降                | N / A                               |

具体迭代内容详见[[复盘.md]]
