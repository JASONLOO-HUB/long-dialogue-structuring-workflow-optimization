# SOP与后端核心逻辑

## 一、 新学习会话SOP设计

为确保用户从模糊意图高效转化为结构化学习路径，新会话的启动遵循一套标准操作程序（SOP），旨在建立“学习契约”，将用户的认知负荷从“规划学什么”解放出来，专注于“理解当前内容”。

-   **Step 1: 意图锚定 (Seed Input & Intent Shaping)**
    -   **交互界面**：系统提供一个“学习意向表单”而非空白对话框，引导用户进行初步的元认知审视。
    -   **核心要素**：表单要求用户明确三个关键信息：
        1.  **目标主题**：例如，“学习Python爬虫”。
        2.  **现有水平**：提供选项，如“零基础”或“具备相关背景知识”。
        3.  **期望深度**：定义学习目标，如“快速上手”或“系统精通”。

-   **Step 2: 蓝图生成 (The Blueprinting)**
    -   **前置规划**：AI不直接开始对话，而是首先在“全景知识地图”界面生成并展示一个结构化的学习蓝图。
    -   **视觉呈现**：该蓝图以“地铁线路图”的形式，清晰展示从初始节点（L1）到最终目标（Ln）的主干学习路径和关键知识点。

-   **Step 3: 路径裁剪 (Collaborative Customization)**
    -   **用户参与**：用户被赋予在大纲地图上进行“剪枝”的权限，将AI生成的蓝图转化为个人定制的学习路径。
    -   **具体操作**：
        -   点击地图节点以标记“跳过”已知内容。
        -   通过拖拽调整章节的先后顺序。

-   **Step 4: 仪式化入场 (The Launch Dive)**
    -   **启动学习**：用户点击“开始学习”后，系统执行一个具有仪式感的过渡动画。
    -   **交互动效**：全景地图以初始节点（L1）为中心进行缩放，随后平滑过渡到双窗口（2-Window）工作区，正式开启沉浸式学习。
    -   **异常处理**：
        -   **慢速生成**：为缓解大纲生成延迟带来的焦虑，系统采用“渐进式渲染”，先展示主干路径，再动态加载分支，并伴有“思考中”的视觉提示。
        -   **自由探索模式**：为满足非结构化学习需求，系统提供一个“自由探索”入口，允许用户跳过SOP直接提问。

## 二、 对话框后端逻辑设计

系统的后端被设计为一个“语义编排层（Orchestration Layer）”，其核心是一个“具备状态的上下文路由器（Stateful Router）”，负责管理状态、意图和长程记忆。

-   **智能路由引擎 (The Intent Router)**
    -   **技术选型**：采用一个极低延迟的轻量级模型（如GPT-4o-mini或本地Qwen-1.5B）作为前置意图分类器。
    -   **意图分类协议**：系统将用户输入精确分类为五种意图，以驱动不同的后端动作：
        -   `STAY`：在当前节点内进行平行业探索或继续追问。
        -   `DIVE`：针对特定概念进行深度挖掘，创建新的子节点。
        -   `BACK`：表示当前节点学习完毕，触发返回上一级的逻辑。
        -   `JUMP`：响应用户在知识地图上的点击，重置主画布以加载目标节点。
        -   `TANGENT`：处理与主学习路径无关的离题内容，将其路由至隔离的临时窗口。

-   **上下文工程：树状记忆协议 (Tree-Context Protocol)**
    -   **核心策略**：为极致优化Token消耗并防止上下文漂移，系统采用“路径压缩上下文（Path-compressed Context）”策略。
    -   **上下文组装结构**：发送给大模型的上下文由四部分精确构成：
        1.  **系统指令 (`C_system`)**: 核心角色定义与输出格式要求。
        2.  **路径摘要 (`C_path_summary`)**: 从根节点到当前节点的摘要链，确保模型知晓其在知识树中的全局位置。
        3.  **父窗口上下文 (`C_parent_window`)**: 左侧Context窗口的最后几轮对话。
        4.  **活跃窗口上下文 (`C_active_window`)**: 右侧Primary窗口的完整当前对话。

-   **知识地图后端状态机 (State Machine)**
    -   **状态持久化**：后端维护一个作为“单一事实来源（Single Source of Truth）”的JSON知识树，用于驱动前端地图的渲染与同步。
    -   **异步总结机制**：当用户离开一个节点时，后端异步触发一个低成本模型，将该节点的对话内容自动总结为一段简短摘要，并存入JSON树中，为路径摘要和冷启动记忆恢复提供数据支持。

-   **模型分层策略 (Model Tiering)**
    -   **路由层**：使用轻量化模型，实现毫秒级意图识别。
    -   **推理层**：使用高性能大模型（如GPT-4o），处理主画布中的复杂逻辑推理。
    -   **总结层**：使用轻量化模型，异步、低成本地处理离场总结任务。

-   **逻辑断裂处理**
    -   **偏移识别**：当用户在一个深层节点（如L4）提出一个与浅层节点（如L2）高度相关的问题时，路由引擎能识别出这种语义偏移。
    -   **智能建议**：后端返回`SUGGEST_JUMP`信号，前端UI会弹出提示，询问用户是否需要直接跳转回之前的相关节点。

## 三、 大纲生成Prompt逻辑 (SOP Step 1)

大纲生成是学习体验的基石，其Prompt设计旨在将知识体系解构为结构化的JSON对象，直接驱动前端“地铁线路图”的生成。

-   **核心逻辑：基于“第一性原理”的解构**
    -   **设计理念**：将复杂知识拆解为“原子级主干（Atomic Trunks）”与“可预测分支（Predictable Branches）”。
    -   **层级定义**：
        -   **L1 (Trunk)**：构成学科的“骨架”，具备强线性逻辑。
        -   **L2 (Dive-in Seeds)**：预判的“认知门槛”，作为潜在的深度钻研点。
        -   **Parallel Seeds**：预判的可对比知识点，用于横向扩展。

-   **Prompt架构设计**
    -   **系统角色 (System Role)**：定义AI为一名“擅长通过第一性原理拆解复杂学科的课程设计师”。
    -   **输入参数 (Input Parameters)**：注入用户在SOP第一步中提供的`Topic`, `User_Level`, `Depth_Expectation`。
    -   **输出约束 (Output Schema)**：强制AI返回严格的JSON结构，包含`id`, `title`, `description`, `parallel_seeds`, 和 `dive_in_seeds`等字段，杜绝任何非结构化文本。

-   **教学法指令：确保“非线性”的可能性**
    -   **逻辑递进**：要求每个L1主干节点是下一个节点的逻辑前提。
    -   **种子机制 (Seeding)**：强制每个节点生成2个`parallel_seeds`和2个`dive_in_seeds`。这些“种子”将作为用户点击“平⾏扩展”或“深层穿透”按钮时的预设Prompt，实现即时响应。
    -   **认知负荷平衡**：指令要求AI根据用户的`User_Level`调整节点标题和描述的术语密度。

-   **压力测试与约束**
    -   **长度控制**：为避免“选择瘫痪”，Prompt明确限制L1主干节点的数量在5-8个之间。
    -   **事实性保障**：为防止AI捏造内容，引入“参考基准（Grounding）”指令，要求其参考公认的教科书或行业标准进行内容生成。

-   **技术落地细节**
    -   **流式解析**：后端采用流式JSON解析器，允许前端在AI生成大纲的过程中就渐进式地渲染地图，优化用户等待体验。
    -   **状态固化**：用户确认后，该JSON大纲即被存入本地数据库，成为本次学习会话的“永久路标”。

## 四、 大纲动态重同步后端逻辑 (The Re-Sync Engine)

为支持用户对AI生成大纲进行手动修改（如剪枝、重命名），后端设计了一套“大纲重同步引擎”，以解决“大纲漂移”问题，确保用户意图与AI逻辑的实时对齐。

-   **局部语义重新建模**
    -   **触发机制**：当用户重命名一个节点时，系统仅针对该节点触发一个“种子刷新任务”，而非重新生成整个大纲。
    -   **目标Prompt**：系统使用一个高度聚焦的Prompt，基于节点的上下文（父节点、子节点）和新的标题，精准地重新生成`parallel_seeds`和`dive_in_seeds`。

-   **逻辑链条一致性检查**
    -   **场景**：当用户删除了一个作为后续章节逻辑基础的节点时。
    -   **“逻辑桥接”机制**：AI自动检查受影响的后续章节，并动态修改其初始Prompt，在其中补充被删除章节的核心前置知识，确保逻辑链的完整性。

-   **拓扑状态持久化**
    -   所有用户的手动修改都会实时写入本地的`study_session.json`文件，该文件是前端渲染的唯一数据源。

-   **压力测试与边缘情况处理**
    -   **离题节点**：若用户插入一个与主线完全无关的节点，路由引擎会将其标记为`TANGENT`属性。在知识地图上，该节点的连接线将以灰色显示，并被排除在核心上下文继承之外。
    -   **成本控制**：为避免频繁修改带来的高昂Token成本，系统采用“懒加载（Lazy Update）”策略。种子的刷新操作被延迟到用户真正点击并进入该修改后节点时才执行。

-   **技术实现：基于图数据的状态管理**
    -   **`logic_hash`校验**：每个节点带有一个`logic_hash`。当一个父节点被修改时，其所有子节点的`logic_hash`将失效，并被标记为“待刷新”状态。
    -   **UI同步**：前端地图上，“待刷新”的节点会显示一个微弱的动画，向用户表明AI正在后台根据其修改调整后续逻辑。

## 五、 记忆加载协议拆解

为实现应用的“秒开”和会话的“无缝恢复”，系统设计了一套“分级上下文水合协议（Hierarchical Context Hydration Protocol）”，核心理念是结构先行、内容懒加载、记忆按需重组。

-   **数据存储架构：轻重分离**
    -   **骨架层 (The Skeleton)**：一个极小的`session_graph.json`文件。它存储节点的ID、标题、层级关系、状态和最重要的**路径摘要 (`path_summary`)**。此文件用于瞬间渲染知识地图的UI结构。
    -   **肌肉层 (The Muscle)**：基于IndexedDB或SQLite，按节点ID存储各个节点的完整对话记录（`node_content_{id}.db`）。此部分数据按需加载，用于填充具体的对话窗口。

-   **冷启动加载时序**
    -   **T+0ms (骨架渲染)**：读取`session_graph.json`，瞬间渲染出顶部缩略图和全景地图的框架，并定位到用户上次会话的最终位置。
    -   **T+100ms (视口水合)**：并行从数据库中读取最后活跃的两个节点（当前节点及其父节点）的完整对话记录，填充双窗口（2-Window）的主画布。此时用户已可阅读，但AI尚未连接。
    -   **T+500ms (记忆重组)**：在后台静默构建发送给LLM的极简上下文，内容包括：全局学习目标、从根节点到当前节点的**路径摘要链**、以及最后两个活跃窗口的摘要和原始对话。
    -   **T+1000ms (连接就绪)**：LLM初始化完成，输入框解锁，用户可开始交互。

-   **核心技术：路径摘要链 (The Path-Summary Chain)**
    -   **离场总结机制 (On-Exit Summarization)**：当用户离开一个对话窗口时，系统自动触发一个后台任务，调用轻量级模型将该窗口的核心结论压缩成百字摘要，并写入骨架层的`summary`字段。
    -   **收益**：在冷启动时，AI只需读取摘要链即可恢复长程记忆，无需重读全部历史对话，极大降低了Token成本并确保了记忆的连续性。

-   **压力测试与边缘情况**
    -   **摘要丢失**：若因异常关闭导致总结任务未执行，系统在冷启动时会即时触发一个补救性的总结任务，并在此期间使用该节点的原始对话作为临时替代品。
    -   **视口预测 (Viewport Prediction)**：为应对用户启动后立即跳转到未加载节点的情况，系统会利用鼠标悬停事件，预先加载用户可能点击的节点的文本数据。

-   **交互体验：无缝衔接的“开场白”**
    -   **智能唤醒 (Smart Wake-up)**：冷启动后，系统会基于上次的会话状态，在输入框上方生成一条“幽灵提示”文本（Ghost Text），如“上次我们停在[核心概念]，需要回顾还是继续？”，该提示由本地规则生成，不消耗LLM Token，但能提供极佳的上下文衔接感。